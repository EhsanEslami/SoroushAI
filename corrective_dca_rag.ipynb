{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import stat\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts.chat import (\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import Document, StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from colorama import Fore\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "#LANGUAGE_MODEL = \"gpt-3.5-turbo-instruct\"\n",
    "LANGUAGE_MODEL = \"gpt-4-turbo\"\n",
    "llm = ChatOpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ارزیاب بازیابی : ارزیاب ارتباط ####\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"امتیاز باینری برای ارزیابی ارتباط اسناد بازیابی‌شده.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(description=\"اسناد نسبت به پرسش کاربر مرتبط هستند: 'بله' یا 'خیر'\")\n",
    "\n",
    "    def get_score(self) -> str:\n",
    "        \"\"\"امتیاز باینری را به صورت رشته برمی‌گرداند.\"\"\"\n",
    "        return self.binary_score\n",
    "\n",
    "\n",
    "def get_score(self) -> str:\n",
    "    \"\"\"امتیاز باینری را به صورت رشته برمی‌گرداند.\"\"\"\n",
    "    return self.binary_score\n",
    "\n",
    "# استفاده از LLM با فراخوانی تابع ساختارمند\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt \n",
    "\n",
    "system_template = \"\"\"تو یک ارزیاب هستی که ارتباط اسناد بازیابی شده زیر:/\n",
    "{documents}/\n",
    "با پرسش کاربر:/\n",
    "{question}/\n",
    "را تعیین می کنید. اگر سند شامل حداقل چند کلمه کاملا یکسان با پرسش باشد و مفهوم کاملا نزدیکی برساند،  آنرا به عنوان مرتبط علامتگداری کرده و پاسخ:\n",
    "بله/\n",
    "و اگر نه پاسخ:\n",
    "خیر/\n",
    "را انتخاب کنید./\n",
    "سعی کن در پاسخ خود سخت گیر باشی و اگر اطمینان نداری که سند مرتبط است پاسخ خیر را انتخاب کنی./\"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    input_variables=[\"documents\", \"question\"],\n",
    "    template=\"{question}\",\n",
    ")\n",
    "grader_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "\n",
    "def load_documents():\n",
    "    \"\"\"\n",
    "    Load all text files from a directory, split them into chunks,\n",
    "    and add metadata with 'doc_id' and 'chunk_index' for each chunk.\n",
    "    \"\"\"\n",
    "    loader = DirectoryLoader(\"./output_text/\", glob=\"*.txt\")  # Load all .txt files\n",
    "    raw_documents = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=100,\n",
    "        chunk_overlap=0,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    \n",
    "    all_chunks = []\n",
    "    for raw_doc in raw_documents:\n",
    "        # Get a document identifier. Here we use the 'source' metadata if available.\n",
    "        doc_id = raw_doc.metadata.get(\"source\", \"unknown\")\n",
    "        chunks = text_splitter.split_text(raw_doc.page_content)\n",
    "        for idx, chunk in enumerate(chunks):\n",
    "            new_doc = Document(page_content=chunk, metadata={\"doc_id\": doc_id, \"chunk_index\": idx})\n",
    "            all_chunks.append(new_doc)\n",
    "    return all_chunks\n",
    "\n",
    "\n",
    "def load_embeddings(documents, user_query):\n",
    "    \"\"\"\n",
    "    Create or load a Chroma vector store from a set of documents.\n",
    "    \"\"\"\n",
    "    persist_directory = './chroma_cache'  # Directory to store embeddings\n",
    "    embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "    # Ensure the directory exists and has write permissions\n",
    "    if not os.path.exists(persist_directory):\n",
    "        os.makedirs(persist_directory, exist_ok=True)\n",
    "    else:\n",
    "        if not os.access(persist_directory, os.W_OK):\n",
    "            print(f\"Error: No write access to {persist_directory}. Fixing permissions...\")\n",
    "            try:\n",
    "                os.chmod(persist_directory, stat.S_IWUSR | stat.S_IRUSR | stat.S_IXUSR)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to change directory permissions: {e}\")\n",
    "                return None\n",
    "\n",
    "    try:\n",
    "        # Load or create Chroma vector store\n",
    "        if not os.listdir(persist_directory):  # Empty directory means no existing DB\n",
    "            print(\"Initializing new ChromaDB instance...\")\n",
    "            db = Chroma.from_documents(documents, embedding_model, persist_directory=persist_directory)\n",
    "            db.persist()\n",
    "        else:\n",
    "            print(\"Loading existing ChromaDB instance...\")\n",
    "            db = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)\n",
    "\n",
    "        # For debugging: perform a similarity search with score and print the top result\n",
    "        docs_with_scores = db.similarity_search_with_score(user_query, k=1)\n",
    "        if docs_with_scores:\n",
    "            top_doc, score = docs_with_scores[0]\n",
    "            print(\"\\nRetrieved Document (for debugging):\\n\")\n",
    "            print(format_docs([top_doc]))\n",
    "            print(\"\\nSimilarity Score:\", score)\n",
    "        else:\n",
    "            print(\"No documents retrieved for the query.\")\n",
    "\n",
    "        return db.as_retriever()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while loading ChromaDB: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_chunk(retriever , query):\n",
    "\n",
    "    retrieved_chunks = retriever.get_relevant_documents(query)\n",
    "    if not retrieved_chunks:\n",
    "        return \"No relevant document found.\"\n",
    "\n",
    "    # Retrieve the top (most relevant) chunk and extract doc_id\n",
    "    top_chunk = retrieved_chunks[0]\n",
    "\n",
    "    return top_chunk.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global documents for dynamic neighbor retrieval\n",
    "documents = load_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing ChromaDB instance...\n",
      "\n",
      "Retrieved Document (for debugging):\n",
      "\n",
      "از بیالفتی است، دل که دل بردید کی ماند ترش، بلبلی گل دید، کی ماند خمشماهی بریانز آسیب خرزر زنده شد،\n",
      "\n",
      "Similarity Score: 0.24009285867214203\n"
     ]
    }
   ],
   "source": [
    "query_text_1 = \"\"\"تفسیر بیت زیر چیست: /\"\n",
    "\"یاد من کن پیش تخت آن عزیز /\n",
    "تا مرا هم واخرد زین حبس نیز\"\"\"\n",
    "\n",
    "query_text_2 = \"\"\"تفسیر بیت زیر چیست: /\n",
    "\n",
    "ای حیات دل حسام‌الدین بسی/\n",
    "میل می‌جوشد به قسم سادسی\"\"\"\n",
    "\n",
    "query_text_3 = \"\"\"تفسیر بیت زیر چیست: /\n",
    "گشت از جذب چو تو علامه‌ای/\n",
    "در جهان گردان حسامی نامه‌ای\"\"\"\n",
    "\n",
    "query_text_4 = \"\"\"تفسیر بیت زیر چیست: /\n",
    "\"عارفی پرسید از آن پیر کشیش/\n",
    "که توی خواجه مسن‌تر یا که ریش\n",
    "\"\"\"\n",
    "\n",
    "query_text_5 = \"\"\"تفسیر بیت زیر چیست: /\n",
    "خواجه‌ای را بود هندو بنده‌ای/\n",
    "پروریده کرده او را زنده‌ای\"\"\"\n",
    "\n",
    "query_text = query_text_2\n",
    "\n",
    "retriever = load_embeddings(documents, query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "از بیالفتی است، دل که دل بردید کی ماند ترش، بلبلی گل دید، کی ماند خمشماهی بریانز آسیب خرزر زنده شد،\n"
     ]
    }
   ],
   "source": [
    "context = top_chunk(retriever, query_text)\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_retrieve_docs(query, context):\n",
    "\n",
    "    retrieval_grader = grader_prompt | structured_llm_grader | get_score\n",
    "    binary_score = retrieval_grader.invoke({\"question\": query, \"documents\": context})\n",
    "    \n",
    "    return binary_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary score: بله\n"
     ]
    }
   ],
   "source": [
    "binary_score = assess_retrieve_docs(query_text, context)\n",
    "print(\"binary score:\", binary_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soroush",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
